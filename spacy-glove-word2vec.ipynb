{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paul Adams\n",
    "### DS7337 Natural Language Processing\n",
    "### Homework 2\n",
    "### May 26, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "import multiprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using 10 (4-gram) of vectors (Paris, France:London, England), do the vector addition and subtraction and compare the vector to the last remaining vectors (aka Paris - France + England compared to London). Do this in GenSim (word2vec)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                    ##################################\n",
    "                                    ##################################\n",
    "\n",
    "                                    ## Word2Vec with Google Corpora ##\n",
    "\n",
    "                                    ##################################\n",
    "                                    ##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '~/GoogleNews-vectors-negative300.bin'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paris + England - France ~ London:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['London' '0.6441212892532349']\n",
      " ['stock_symbol_BNK' '0.5432794094085693']\n",
      " ['ticker_symbol_BNK' '0.5106071829795837']\n",
      " ['LSO_St_Lukes' '0.474970281124115']\n",
      " ['Leeds' '0.465692400932312']\n",
      " ['Englands' '0.4634588956832886']\n",
      " ['Islamabad_Slyvia_Hui' '0.46285343170166016']\n",
      " ['Manchester' '0.4587923288345337']\n",
      " ['Covent_Garden' '0.4549728333950043']\n",
      " ['Kensington' '0.4531983435153961']]\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['Paris', 'England'], negative=['France'], topn=10)\n",
    "print(np.asanyarray(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity of predicted target, London:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52644765"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.cosine_similarities(model.wv['London'], [model.wv['Paris'] + model.wv['Germany'] - model.wv['France']])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moscow + Czech - Russia ~ Prague:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Prague' '0.7071495056152344']\n",
      " ['Slovak' '0.7055152654647827']\n",
      " ['Bratislava' '0.6522541046142578']\n",
      " ['Slovakian' '0.6387290358543396']\n",
      " ['Hungarian' '0.6330443620681763']\n",
      " ['Polish' '0.6241848468780518']\n",
      " ['Budapest' '0.6221982836723328']\n",
      " ['Romanian' '0.6159559488296509']\n",
      " ['Latvian' '0.6095941066741943']\n",
      " ['Plzen' '0.6003187298774719']]\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['Moscow', 'Czech'], negative=['Russia'], topn=10)\n",
    "print(np.asanyarray(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity of predicted target, Prague:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72820634"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.cosine_similarities(model.wv['Prague'], [model.wv['Moscow'] + model.wv['Czech'] - model.wv['Russia']])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dallas + Georgia - Texas ~ Atlanta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Atlanta' '0.7178083658218384']\n",
      " ['Newnan' '0.5695133209228516']\n",
      " ['metro_Atlanta' '0.5685676336288452']\n",
      " ['Gwinnett' '0.5642828941345215']\n",
      " ['Lithonia' '0.5615620613098145']\n",
      " ['Alpharetta' '0.5454471707344055']\n",
      " ['Jacksonville' '0.5440741777420044']\n",
      " ['Statesboro' '0.5386471152305603']\n",
      " ['Cartersville' '0.5383665561676025']\n",
      " ['Tbilisi' '0.5380100011825562']]\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['Dallas', 'Georgia'], negative=['Texas'], topn=10)\n",
    "print(np.asanyarray(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity of predicted target, Atlanta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71677387"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.cosine_similarities(model.wv['Atlanta'], [model.wv['Dallas'] + model.wv['Georgia'] - model.wv['Texas']])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bamako + Niger - Mali ~ Niamey:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Niamey' '0.6093408465385437']\n",
      " ['Nigerien' '0.5689219832420349']\n",
      " ['capital_Niamey' '0.566901683807373']\n",
      " ['Banjul' '0.5426015853881836']\n",
      " ['Kinshasa' '0.5206555128097534']\n",
      " ['Abuja' '0.5101810693740845']\n",
      " ['Ouagadougou' '0.5079010725021362']\n",
      " ['Yaounde' '0.5075834393501282']\n",
      " ['Conakry' '0.5001047253608704']\n",
      " [\"N'djamena\" '0.4985504746437073']]\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['Bamako', 'Niger'], negative=['Mali'], topn=10)\n",
    "print(np.asanyarray(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity of predicted target, Niamey:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67026013"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.cosine_similarities(model.wv['Niamey'], [model.wv['Bamako'] + model.wv['Niger'] - model.wv['Mali']])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuuk + Iceland - Greenland ~ Reykjavic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Reykjavik' '0.6092618107795715']\n",
      " ['Icelandic' '0.5589416027069092']\n",
      " ['Reykjavík' '0.5301437973976135']\n",
      " ['Jón' '0.5204928517341614']\n",
      " ['Ólafur' '0.5089145302772522']\n",
      " ['Akureyri' '0.504554033279419']\n",
      " ['Vilhjálmsson' '0.48889362812042236']\n",
      " ['Torshavn' '0.488788902759552']\n",
      " ['Jónsson' '0.4843323826789856']\n",
      " ['Árni' '0.4761621356010437']]\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['Nuuk', 'Iceland'], negative=['Greenland'], topn=10)\n",
    "print(np.asanyarray(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity of predicted target, Reykjavic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6187233"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.cosine_similarities(model.wv['Reykjavik'], [model.wv['Nuuk'] + model.wv['Iceland'] - model.wv['Greenland']])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rome + Austria - Italy ~ Vienna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Vienna' '0.6124913692474365']\n",
      " ['Budapest' '0.5570676922798157']\n",
      " ['Austrian' '0.5518302917480469']\n",
      " ['Linz' '0.5456212759017944']\n",
      " ['Berlin' '0.5427166223526001']\n",
      " ['Munich' '0.5372970104217529']\n",
      " ['Salzburg' '0.525149405002594']\n",
      " ['Lausanne' '0.518720269203186']\n",
      " ['Thessalonica' '0.5157889723777771']\n",
      " ['Bratislava' '0.5157566070556641']]\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['Rome', 'Austria'], negative=['Italy'], topn=10)\n",
    "print(np.asanyarray(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity of predicted target, Vienna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61858284"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.cosine_similarities(model.wv['Vienna'], [model.wv['Rome'] + model.wv['Austria'] - model.wv['Italy']])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canberra + Indonesia - Australia ~ Jakarta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Jakarta' '0.7600908279418945']\n",
      " ['Indonesian' '0.6817788481712341']\n",
      " ['Yogyakarta' '0.6003887057304382']\n",
      " ['Riau' '0.5932705402374268']\n",
      " ['Agung' '0.5806156396865845']\n",
      " ['Denpasar' '0.5798360109329224']\n",
      " ['Surabaya' '0.5790249705314636']\n",
      " ['Pekanbaru' '0.5784623026847839']\n",
      " ['Susilo' '0.5784249901771545']\n",
      " ['President_Megawati_Soekarnoputri' '0.5781753063201904']]\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['Canberra', 'Indonesia'], negative=['Australia'], topn=10)\n",
    "print(np.asanyarray(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity of predicted target, Jakarta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77504253"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.cosine_similarities(model.wv['Jakarta'], [model.wv['Canberra'] + model.wv['Indonesia'] - model.wv['Australia']])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delhi + Bangladesh - India ~ Dhaka:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Dhaka' '0.7852472066879272']\n",
      " ['Chittagong' '0.6785155534744263']\n",
      " ['Bogra' '0.6287319660186768']\n",
      " ['Sylhet' '0.6267374753952026']\n",
      " ['Dhaka_Bangladesh' '0.6262991428375244']\n",
      " ['Mirpur' '0.6200497150421143']\n",
      " ['Bangladeshi' '0.5985468626022339']\n",
      " ['Kolkata' '0.5969777703285217']\n",
      " ['Shariatpur' '0.594900369644165']\n",
      " ['Rajshahi' '0.5928016901016235']]\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['Delhi', 'Bangladesh'], negative=['India'], topn=10)\n",
    "print(np.asanyarray(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity of predicted target, Dhaka:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8147708"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.cosine_similarities(model.wv['Dhaka'], [model.wv['Delhi'] + model.wv['Bangladesh'] - model.wv['India']])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Athens + Croatia - Greece ~ Zagreb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Zagreb' '0.6733443737030029']\n",
      " ['Belgrade' '0.5434583425521851']\n",
      " ['Podgorica' '0.5366973280906677']\n",
      " ['Croatian' '0.529181718826294']\n",
      " ['Serbia' '0.5110309720039368']\n",
      " ['Sarajevo' '0.5010828971862793']\n",
      " ['Croatians' '0.5000446438789368']\n",
      " ['Serbia_Montenegro' '0.48928573727607727']\n",
      " ['Jagodina' '0.4879768490791321']\n",
      " ['Novi_Sad_Serbia' '0.48574817180633545']]\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['Athens', 'Croatia'], negative=['Greece'], topn=10)\n",
    "print(np.asanyarray(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity of predicted target, Zagreb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66271394"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.cosine_similarities(model.wv['Zagreb'], [model.wv['Athens'] + model.wv['Croatia'] - model.wv['Greece']])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managua + Venezuela - Nicaragua ~ Caracas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Caracas' '0.7959936857223511']\n",
      " ['Venezuelan' '0.6667956709861755']\n",
      " ['Quito' '0.6146404147148132']\n",
      " ['Chávez' '0.6103371381759644']\n",
      " ['Caracas_Venezuela' '0.6047829389572144']\n",
      " ['Venezuelans' '0.6025427579879761']\n",
      " ['Chavez' '0.5986135601997375']\n",
      " ['Maracaibo' '0.5953344702720642']\n",
      " ['President_Hugo_Chavez' '0.576349139213562']\n",
      " ['Havana' '0.5716559886932373']]\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['Managua', 'Venezuela'], negative=['Nicaragua'], topn=10)\n",
    "print(np.asanyarray(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity of predicted target, Caracas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8201996"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.cosine_similarities(model.wv['Caracas'], [model.wv['Managua'] + model.wv['Venezuela'] - model.wv['Nicaragua']])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Repeat the exercise in SpaCy (glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                    #######################################\n",
    "                                    #######################################\n",
    "\n",
    "                                    ## Spacy with EN_CORE_WEB_LG Corpora ##\n",
    "\n",
    "                                    #######################################\n",
    "                                    #######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One important thing to note about Glove (spacy) is that Glove is trained globally to preserve the statistical aspect to NLP, which Stanford has determined very important to solving NLP problems. There is an apparent trade-off between the two approaches (Word2Vec vs. Glove) since localized context is more important for Word2Vec and globalized context is more important in Glove that manifests in this assignment to show that Word2Vec is more accurate overall for pairing cities and states or countries than Glove. However, Glove may better pair phrases and sentences than Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_lg\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(start_word, add_word, sub_word):\n",
    "    import numpy as np\n",
    "\n",
    "    target_word = (nlp.vocab[start_word].vector - nlp.vocab[sub_word].vector + nlp.vocab[add_word].vector)\n",
    "    target_word_array = np.asanyarray([target_word])\n",
    "    most_similar_word = nlp.vocab.vectors.most_similar(target_word_array, n=10)\n",
    "\n",
    "    closest_word = []\n",
    "\n",
    "    for i in most_similar_word[0].tolist()[0]:\n",
    "        try:\n",
    "            closest_word.append((nlp.vocab[i].text, most_similar_word[2].tolist()[0][most_similar_word[0].tolist()[0].index(i)]))\n",
    "        except:\n",
    "            closest_word.append(None)\n",
    "\n",
    "    return closest_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(sentence):\n",
    "    import numpy as np\n",
    "\n",
    "    target_word = the_sentence = nlp(sentence).vector.mean()\n",
    "    target_word_array = np.asanyarray([target_word])\n",
    "    most_similar_word = nlp.vocab.vectors.most_similar(target_word_array, n=10)\n",
    "\n",
    "    closest_word = []\n",
    "\n",
    "    for i in most_similar_word[0].tolist()[0]:\n",
    "        try:\n",
    "            closest_word.append((nlp.vocab[i].text, most_similar_word[2].tolist()[0][most_similar_word[0].tolist()[0].index(i)]))\n",
    "        except:\n",
    "            closest_word.append(None)\n",
    "\n",
    "    return closest_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float32' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9cfc319a3776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_closest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-dc42a7494131>\u001b[0m in \u001b[0;36mfind_closest\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtarget_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthe_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtarget_word_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_word\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmost_similar_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_word_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0;34m'An'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m             raise ValueError(Errors.E088.format(length=len(text),\n\u001b[1;32m    339\u001b[0m                                                 max_length=self.max_length))\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.float32' has no len()"
     ]
    }
   ],
   "source": [
    "find_closest(the_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_sentence = nlp('the car jumped over the fence').vector.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "find_closest() missing 2 required positional arguments: 'add_word' and 'sub_word'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9cfc319a3776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_closest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: find_closest() missing 2 required positional arguments: 'add_word' and 'sub_word'"
     ]
    }
   ],
   "source": [
    "find_closest(the_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1654d5bd0ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmost_similar_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'the car jumped over the fence'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mvectors.pyx\u001b[0m in \u001b[0;36mspacy.vectors.Vectors.most_similar\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2559\u001b[0m             \u001b[0;31m# special case for speedup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2560\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2561\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2562\u001b[0m         \u001b[0;31m# None of the str-type keywords for ord ('fro', 'nuc')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0;31m# are valid for vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "most_similar_word = nlp.vocab.vectors.most_similar(the_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "#####\n",
    "\n",
    "# something else from medium: https://medium.com/better-programming/the-beginners-guide-to-similarity-matching-using-spacy-782fc2922f7c\n",
    "\n",
    "#####\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_similarity(word1, word2):\n",
    "    word1 = nlp(word1)\n",
    "    word2 = nlp(word2)\n",
    "    return word1.similarity(word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5824116666593889"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity('Paris','Rome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6358075873317459"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity('Paris', 'Lyon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity('Paris','Paris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "684830"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.vectors.n_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(start_word, add_word, sub_word):\n",
    "    import numpy as np\n",
    "\n",
    "    target_word = (nlp.vocab[start_word].vector - nlp.vocab[sub_word].vector + nlp.vocab[add_word].vector)\n",
    "    target_word_array = np.asanyarray([target_word])\n",
    "    most_similar_word = nlp.vocab.vectors.most_similar(target_word_array, n=10)\n",
    "\n",
    "    closest_word = []\n",
    "\n",
    "    for i in most_similar_word[0].tolist()[0]:\n",
    "        try:\n",
    "            closest_word.append((nlp.vocab[i].text, most_similar_word[2].tolist()[0][most_similar_word[0].tolist()[0].index(i)]))\n",
    "        except:\n",
    "            closest_word.append(None)\n",
    "\n",
    "    return closest_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paris + England - France ~ London:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('england', 0.7861999869346619),\n",
       " ('England', 0.7861999869346619),\n",
       " ('ENGLAND', 0.7861999869346619),\n",
       " ('london', 0.7662000060081482),\n",
       " ('LONDON', 0.7662000060081482),\n",
       " ('London', 0.7662000060081482),\n",
       " ('manchester', 0.6877999901771545),\n",
       " ('Manchester', 0.6877999901771545),\n",
       " ('MANCHESTER', 0.6877999901771545),\n",
       " ('York', 0.6640999913215637)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest('Paris','England','France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7661834359169006\n"
     ]
    }
   ],
   "source": [
    "similarity = 1 - (distance.cosine(nlp('London').vector, (nlp('Paris').vector + nlp('England').vector - nlp('France').vector)))\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moscow + Czech (Republic or -ia) - Russia ~ Prague:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('czech', 0.7839000225067139),\n",
       " ('CZECH', 0.7839000225067139),\n",
       " ('Czech', 0.7839000225067139),\n",
       " ('PRAGUE', 0.6628000140190125),\n",
       " ('prague', 0.6628000140190125),\n",
       " ('Prague', 0.6628000140190125),\n",
       " ('MOSCOW', 0.6315000057220459),\n",
       " ('moscow', 0.6315000057220459),\n",
       " ('Moscow', 0.6315000057220459),\n",
       " ('Hungarian', 0.6276999711990356)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest('Moscow','Czech','Russia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6627671122550964\n"
     ]
    }
   ],
   "source": [
    "similarity = 1 - (distance.cosine(nlp('Prague').vector, (nlp('Moscow').vector + nlp('Czech').vector - nlp('Russia').vector)))\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dallas + Georgia - Texas ~ Atlanta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ATLANTA', 0.8543999791145325),\n",
       " ('Atlanta', 0.8543999791145325),\n",
       " ('atlanta', 0.8543999791145325),\n",
       " ('GEORGIA', 0.8409000039100647),\n",
       " ('georgia', 0.8409000039100647),\n",
       " ('Georgia', 0.8409000039100647),\n",
       " ('Dallas', 0.7705000042915344),\n",
       " ('DALLAS', 0.7705000042915344),\n",
       " ('dallas', 0.7705000042915344),\n",
       " ('COLUMBUS', 0.7369999885559082)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest('Dallas','Georgia','Texas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8544327020645142\n"
     ]
    }
   ],
   "source": [
    "similarity = 1 - (distance.cosine(nlp('Atlanta').vector, (nlp('Dallas').vector + nlp('Georgia').vector - nlp('Texas').vector)))\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bamako + Niger - Mali ~ Niamey:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('niger', 0.6607999801635742),\n",
       " ('NIGER', 0.6607999801635742),\n",
       " ('Niger', 0.6607999801635742),\n",
       " ('Bamako', 0.6420999765396118),\n",
       " ('bamako', 0.6420999765396118),\n",
       " ('LIBREVILLE', 0.48010000586509705),\n",
       " ('Libreville', 0.48010000586509705),\n",
       " ('libreville', 0.48010000586509705),\n",
       " ('albus', 0.4602999985218048),\n",
       " ('Albus', 0.4602999985218048)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest('Bamako','Niger','Mali')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Niamey either is not in the en_core_web_lg vocabulary or the cosine proximity to Bamako is so great that it is not considered similary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "similarity = 1 - (distance.cosine(nlp('Niamey').vector, (nlp('Bamako').vector + nlp('Niger').vector - nlp('Mali').vector)))\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuuk + Iceland - Greenland ~ Reykjavik:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Greenland', 0.5764999985694885),\n",
       " ('greenland', 0.5764999985694885),\n",
       " ('GREENLAND', 0.5764999985694885),\n",
       " ('Earhart', 0.320499986410141),\n",
       " ('earhart', 0.320499986410141),\n",
       " ('EARHART', 0.320499986410141),\n",
       " ('SHATTUCK', 0.3010999858379364),\n",
       " ('Shattuck', 0.3010999858379364),\n",
       " ('shattuck', 0.3010999858379364),\n",
       " ('PADDLES', 0.3003999888896942)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest('Nuuk','Greenland','Iceland')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As with Bamako and Niamey, Nuuk and Reykjavic seem to either have a high distance between each other or Reyjkavic is not in the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "similarity = 1 - (distance.cosine(nlp('Reykjavic').vector, (nlp('Nuuk').vector + nlp('Greenland').vector - nlp('Iceland').vector)))\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rome + Austria - Italy ~ Vienna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Austria', 0.7305999994277954),\n",
       " ('austria', 0.7305999994277954),\n",
       " ('AUSTRIA', 0.7305999994277954),\n",
       " ('Rome', 0.7253999710083008),\n",
       " ('ROME', 0.7253999710083008),\n",
       " ('rome', 0.7253999710083008),\n",
       " ('VIENNA', 0.6216999888420105),\n",
       " ('Vienna', 0.6216999888420105),\n",
       " ('vienna', 0.6216999888420105),\n",
       " ('prague', 0.6072999835014343)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest('Rome','Austria','Italy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6216548085212708\n"
     ]
    }
   ],
   "source": [
    "similarity = 1 - (distance.cosine(nlp('Vienna').vector, (nlp('Rome').vector + nlp('Austria').vector - nlp('Italy').vector)))\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canberra + Indonesia - Australia ~ Jakarta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('INDONESIA', 0.7560999989509583),\n",
       " ('Indonesia', 0.7560999989509583),\n",
       " ('indonesia', 0.7560999989509583),\n",
       " ('INDONESIAN', 0.6470999717712402),\n",
       " ('indonesian', 0.6470999717712402),\n",
       " ('Indonesian', 0.6470999717712402),\n",
       " ('jakarta', 0.6407999992370605),\n",
       " ('Jakarta', 0.6407999992370605),\n",
       " ('JAKARTA', 0.6407999992370605),\n",
       " ('BANDUNG', 0.6169999837875366)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest('Canberra','Indonesia','Australia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6408481597900391\n"
     ]
    }
   ],
   "source": [
    "similarity = 1 - (distance.cosine(nlp('Jakarta').vector, (nlp('Canberra').vector + nlp('Indonesia').vector - nlp('Australia').vector)))\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delhi + Bangladesh - India ~ Dhaka:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bangladesh', 0.7764999866485596),\n",
       " ('bangladesh', 0.7764999866485596),\n",
       " ('BANGLADESH', 0.7764999866485596),\n",
       " ('dhaka', 0.7304999828338623),\n",
       " ('Dhaka', 0.7304999828338623),\n",
       " ('DHAKA', 0.7304999828338623),\n",
       " ('DELHI', 0.718500018119812),\n",
       " ('Delhi', 0.718500018119812),\n",
       " ('delhi', 0.718500018119812),\n",
       " ('Kolkata', 0.6664999723434448)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest('Delhi','Bangladesh','India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7305277585983276\n"
     ]
    }
   ],
   "source": [
    "similarity = 1 - (distance.cosine(nlp('Dhaka').vector, (nlp('Delhi').vector + nlp('Bangladesh').vector - nlp('India').vector)))\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Athens + Croatia - Greece ~ Zagreb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('croatia', 0.7390000224113464),\n",
       " ('Croatia', 0.7390000224113464),\n",
       " ('CROATIA', 0.7390000224113464),\n",
       " ('ZAGREB', 0.6495000123977661),\n",
       " ('Zagreb', 0.6495000123977661),\n",
       " ('zagreb', 0.6495000123977661),\n",
       " ('dubrovnik', 0.6431000232696533),\n",
       " ('DUBROVNIK', 0.6431000232696533),\n",
       " ('Dubrovnik', 0.6431000232696533),\n",
       " ('Athens', 0.6176999807357788)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest('Athens','Croatia','Greece')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6495274901390076\n"
     ]
    }
   ],
   "source": [
    "similarity = 1 - (distance.cosine(nlp('Zagreb').vector, (nlp('Athens').vector + nlp('Croatia').vector - nlp('Greece').vector)))\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managua + Venezuela - Nicaragua ~ Managua:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('managua', 0.7656999826431274),\n",
       " ('Managua', 0.7656999826431274),\n",
       " ('MANAGUA', 0.7656999826431274),\n",
       " ('VENEZUELA', 0.7091000080108643),\n",
       " ('venezuela', 0.7091000080108643),\n",
       " ('Venezuela', 0.7091000080108643),\n",
       " ('CARACAS', 0.6435999870300293),\n",
       " ('caracas', 0.6435999870300293),\n",
       " ('Caracas', 0.6435999870300293),\n",
       " ('maracaibo', 0.5892999768257141)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest('Managua','Venezuela','Nicaragua')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6436408162117004\n"
     ]
    }
   ],
   "source": [
    "similarity = 1 - (distance.cosine(nlp('Caracas').vector, (nlp('Managua').vector + nlp('Venezuela').vector - nlp('Nicaragua').vector)))\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The results from Gensim (Word2Vec) are more accurate than the results using SpaCy (Glove) for this application. This could be because of the way the two models are trained. Whereas Gensim is trained locally, SpaCy is trained globally so SpaCy may be considering more contexts than Gensim. These additional contexts could result in noise presented as unexpected similarities for what is searched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare the same vectors from Spacy and Gensim. Can you mix the vectors from each group?\n",
    "### Although the vectors created by each process have a total length of 300 and can therefore mathematically be mixed, they cannot be mixed together for practical application because of the difference in approach to word embedding Gensim and SpaCy each applies.\n",
    "\n",
    "### An example of mixing word vectors is below. The math works, but the result is not reliable. When measuring the cosine similarity using the Gensim built-in measurement, there are different results performing the same operation when using SpaCy's vector for 'Georgia' versus Gensim's vector for 'Georgia'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SpaCy's vector length for 'Georgia':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp('Georgia').vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gensim's vector length for embedded 'Georgia':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['Georgia'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dallas (Gensim) + Georgia (SpaCy) - Texas (Gensim):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1327803"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.cosine_similarities(model.wv['Atlanta'], [model.wv['Dallas'] + nlp('Georgia').vector - model.wv['Texas']])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dallas + Georgia - Texas (all in Gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71677387"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.cosine_similarities(model.wv['Atlanta'], [model.wv['Dallas'] + model.wv['Georgia'] - model.wv['Texas']])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using the SciPy distance formula, compare your results in SpaCy to this formula. What is the difference? What was changed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The difference is that in SciPy, similarity is equal to 1 minus the distance value. In SpaCy, similarity is obtained directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SciPy cosine distance for comparing 'Atlanta' to Dallas + Georgia - Texas ~ Atlanta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "SciPy_Dist = distance.cosine(nlp('Atlanta').vector, (nlp('Dallas').vector + nlp('Georgia').vector - nlp('Texas').vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SciPy distance between 'Atlanta' and Dallas + Georgia - Texas ~ Atlanta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14556729793548584"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SciPy_Dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SciPy similarity between 'Atlanta' and Dallas + Georgia - Texas ~ Atlanta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATLANTA: 0.8544327020645142\n"
     ]
    }
   ],
   "source": [
    "SciPy_Similarity = 1 - SciPy_Dist\n",
    "print(\"ATLANTA:\", SciPy_Similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using SpaCy distance to show the similarity between Dallas + Georga - Texas and Atlanta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ATLANTA', 0.8543999791145325)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest('Dallas','Georgia','Texas')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Manually verify the distance calculations (aka write your own formula) for Spacy Similarity and Scipy (cosine) similarity. Did you match up the exact results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the example used (Dallas + Georgia - Texas ~ Atlanta), the results were all very close (when rounded, to the ten-thousandth's decimal place) between all three methods, but none were identical. SpaCy and SciPy had the closest similarities (to the ten-millionth's decimal place)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual Cosine Similarity Calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(v1, v2):\n",
    "    return sum(x*y for x,y in zip(v1,v2)) # zip() to aggregate the vectors into tuples\n",
    "\n",
    "def similarity(a,b):\n",
    "    import numpy as np\n",
    "\n",
    "    return dot_product(a,b)/(np.sqrt(dot_product(a,a))*np.sqrt(dot_product(b,b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually calculated cosine similarity for the SpaCy vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATLANTA: 0.8544327816781538\n"
     ]
    }
   ],
   "source": [
    "manual_similarity = similarity(nlp('Atlanta').vector, (nlp('Dallas').vector + nlp('Georgia').vector - nlp('Texas').vector))\n",
    "print(\"ATLANTA:\", manual_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SpaCy API cosine similarity calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ATLANTA', 0.8543999791145325)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest('Dallas','Georgia','Texas')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SciPy cosine distance converted to similarity calculation for SpaCy vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATLANTA: 0.8544327020645142\n"
     ]
    }
   ],
   "source": [
    "SciPy_Dist = distance.cosine(nlp('Atlanta').vector, (nlp('Dallas').vector + nlp('Georgia').vector - nlp('Texas').vector))\n",
    "SciPy_Similarity = 1 - SciPy_Dist\n",
    "print(\"ATLANTA:\", SciPy_Similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paul Adams\n",
    "# DS7337 Natural Language Processing\n",
    "# Final Exam\n",
    "# 9 August 2020\n",
    "\n",
    "1. [Build a model then predict the sentiment based on a sequence of characters and a second model based on a sequence of bi-grams](#question1)\n",
    "    1. [Sequence of Unigram Characters Model - Start](#question1a)\n",
    "        1. [Sequence of Unigram Characters Model - Model Results](#question1ab)\n",
    "    2. [Sequence of Bi-Gram Characters Model](#question1b)\n",
    "        1. [Sequence of Bi-Gram Characters Model - Model Results](#question1bb)\n",
    "2. [What is the vector you learned for the following emoji?](#question1ca)\n",
    "    1. [Unigram Model Output for Emoji Embedding](#question1cb)\n",
    "    2. [The vector learned for the emoji: üòÇ](#question1cc)\n",
    "        1. [Loading the saved model](#question1cd)\n",
    "        2. [Load the saved word list](#question1ce)\n",
    "        3. [The learned vector for üòÇ](#question1cf)\n",
    "3. [What is the most similar character for the emoji üòÇ?](#question1da)\n",
    "4. [Build a Universal Sentence Encoder (USE) Model and GRU](#question1e)\n",
    "    1. [Universal Sentence Encoder Models](#question1ea)\n",
    "        1. [USE Model Results](#question1eb)\n",
    "    2. [Gated Recurrent Unit Models](#question1ec)\n",
    "        1. [GRU Model Results](#question1ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "# display 400 characters of column width\n",
    "pd.options.display.max_colwidth = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tensorflow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PART I: Sequence of Characters (Unigram) Model**  <a class=\"anchor\" id=\"question1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the GOP twitter dataset (a dataset of tweets from 2012 with 3 sentiments‚Äîsee the attached file)\n",
    "\n",
    "# 1. Build a model then predict the sentiment (column ‚ÄúSentiment‚Äù) of the tweet based on a sequence of characters and a second model based on a sequence of bi-grams (2-letter sequences)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to use Gated Recurrent Unit (GRU) - as opposed to a Recurrent Neural Net (RNN) - because of the high volume of incomprehensible words such as hashtags (GOPdebate is one of the top words used in the whole dataset) and misspellings in the tweets. My opinion is that these words contribute greatly to the lack of confidence indicated in the tweet sentiment confidence provided for the pre-labeled sentiment classes.\n",
    "\n",
    "Additionally, there are words that appear to have deep cultural meaning, such as the previously mentioned hashtags. I left these words in because the GRU can consider wider ranges of the sentence sequences simultaneously, thus capturing more of the context in which these words are repeatedly framed. For example, GOPdebate; while this word doesn't necessarily mean anything in terms of a word you would find in a traditional, academically accepted lexicon, there is underlying meaning which GRU is able to extract without resulting in a significant issue of vanishing gradients during back-propogation (an issue an RNN would likely suffer from). Therefore, by capturing meaning from these contexts, GRU is able to keep meaningful weights and biases for nodes that would otherwise be minimized from those vanishing gradients and thus result in the model's failure to continue learning. For this reason, I selected GRU as my model of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important to note is that the provided confidence of the pre-labeling of Tweet sentiments is roughly 76%. Therefore, the benchmark of perfect model accuracy should approximate this value. Please see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The average confidence of all pre-scored sentiments: {}%\".format(100*round(df['sentiment_confidence'].mean(),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti = df[['sentiment','text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA-CLEANING-START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_specials(doc):\n",
    "    \"\"\" removes all but alphanumeric, newline escape characters, and replaces hyphens with spaces for hyphenated words to not become one, but two\"\"\"\n",
    "    doc = re.sub('-', ' ', doc)\n",
    "    doc = re.sub('_', ' ', doc)\n",
    "    pattern = r\"[^a-zA-z0-9\\s]+\"\n",
    "    doc = re.sub(pattern, '', doc)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This is a three-target-class predictive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti['sentiment'].replace(\"Negative\", 0, inplace=True)\n",
    "df_senti['sentiment'].replace(\"Neutral\", 1, inplace=True)\n",
    "df_senti['sentiment'].replace(\"Positive\", 2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_senti['text'] = df_senti['text'].str.replace('http://', '', case=False)\n",
    "# df_senti['text'] = df_senti['text'].str.replace('https://', '', case=False)\n",
    "# df_senti['text'] = df_senti['text'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
    "# df_senti['text'] = df_senti['text'].str.replace('https\\S+|www.\\S+', '', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0, len(df_senti)):\n",
    "    if df_senti['text'][i].strip()[0:2] == \"RT\":\n",
    "        df_senti['text'][i] = df_senti['text'][i][2:]\n",
    "    \n",
    "    df_senti['text'][i] = remove_specials(df_senti['text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0,len(df_senti)):\n",
    "    df_senti['text'][i] = ' '.join(word for word in df_senti['text'][i].split(' ') if not word.startswith('http'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti['text'] = df_senti['text'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti['text'].str.strip().isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(len(df_senti['text'])):\n",
    "    df_senti['text'][i] = df_senti['text'][i].replace('\\\\n', ' ')\n",
    "    \n",
    "for i in np.arange(len(df_senti['text'])):\n",
    "    df_senti['text'][i] = df_senti['text'][i].replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti.iloc[0,1].replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args=pd.DataFrame()\n",
    "args=[]\n",
    "\n",
    "for j in range(len(df_senti)):\n",
    "    args.append(list([df_senti.iloc[j,1].replace(' ', '')[i:i+1] for i in range(len(df_senti.iloc[j,1].replace(' ', '')))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_frame = pd.Series(args).replace('', '')\n",
    "args_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(len(args_frame)):\n",
    "    args_frame[i] = ' '.join(args_frame[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti2 = pd.concat([df_senti['sentiment'],args_frame], axis=1)\n",
    "df_senti2.columns = ['sentiment','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA-CLEANING-EXIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for adding the tweet words into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put words into a dictionary for downstream use\n",
    "import collections\n",
    "def build_dataset(words):\n",
    "    count = collections.Counter(words).most_common() #.most_common(100) to use the 100 most common words; .most_common() means zero is the most common\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding and decoding for the tweets, based on the word list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "\n",
    "for i in df_senti2['text']:\n",
    "    word_list = word_list + i.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_decode(input):\n",
    "    enc, dec = build_dataset(word_list)\n",
    "    return enc, dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc, dec = encode_decode(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing padding and unknown tokens for each sequence (sentence). Tokens will be added downstream with pad_sequences().\n",
    "\n",
    "Start by shifting all sequences by two places to insert in a pad token and an unknown token in index locations 0 and 1. These will be specified within the keras pre-processing pad_sequences function downstream once the desired maximum sequence length is determined based on sentence length distribution analysis. These tokens will be added to both the encoded and decoded.\n",
    "\n",
    "Including an unknown token in the validation data is helpful for ensuring the model can avoid bias based on the words it knows in the event it encounters a new word it doesn't know. The patterns around the unknown word could match to the unknown marker so in the event there truly is a new word or new context for a word used, it will provide inference based on the pattern of the context rather than force it to match meaning to a word it does know, but does not apply for the context. This helps the model provide meaning to the context of what is being said rather than the words used, such as in the example \"I'm feeling blue because something happened\" vs. \"the sky is blue because something happened.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in enc:\n",
    "    enc[i] = enc[i]+2 # shift everything by two so you can put in a pad and an unknown in index locations 0 and 1\n",
    "\n",
    "                                                                    ###      ###\n",
    "                                                                    # Encoding #\n",
    "                                                                    ###      ###\n",
    "enc['pad'] = 0\n",
    "\n",
    "# start is useful for more complex architectures to invoke the LSTM to perform certain tasks, like decoding or recognizing the start of a sentence, for example.\n",
    "#enc['<start>'] = 1\n",
    "\n",
    "enc['<unk>'] = 1\n",
    "\n",
    "                                                                    ###      ###\n",
    "                                                                    # Decoding #\n",
    "                                                                    ###      ###\n",
    "\n",
    "# pad and include an unknown for the decoded values as well\n",
    "dec[-2]='<pad>'\n",
    "#dec[-1]='<start>'\n",
    "dec[-1]='<unk>' # this is useful to indicate the LSTM should start decoding, or that this is the start of a sentence, or etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n=int(np.floor(df_senti2.shape[0]*0.75)) # 75% for training\n",
    "train = df_senti2[0:n]\n",
    "test = df_senti2[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing train/test split balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional training data balancing approach (consider the trade-off between overfitting and bias before committing to downsampling classes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to balance the training data:\n",
    "\n",
    "# df1 = train[train['sentiment'] == 0]\n",
    "# df1 = df1[:1701]\n",
    "\n",
    "# df2 = train[train['sentiment'] == 1]\n",
    "# df2 = df2[:1701]\n",
    "\n",
    "# df3 = train[train['sentiment'] == 2]\n",
    "\n",
    "# train = pd.concat([df1, df2, df3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti2['y'] = 0\n",
    "df_senti2.loc[df_senti2['sentiment']==1,'y'] = 1\n",
    "df_senti2.loc[df_senti2['sentiment']==2,'y'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating test examples for encoding and decoding sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "\n",
    "for i in range(train.shape[0]):\n",
    "    tmp = [enc[j] for j in train.iloc[i,1].split()] # enc[j]: the j (list expression) is encoding the number for the word in the encoded matrix (i,j) \n",
    "    x_train.append(tmp) # append the newly replaced word\n",
    "    if train.iloc[i,0]==0: # re-encode y in the below\n",
    "        y=0\n",
    "    elif train.iloc[i,0]==1: # re-encode y in the below\n",
    "        y=1\n",
    "    else:\n",
    "        y=2\n",
    "    y_train.append(y) # append the newly encoded y here\n",
    "    \n",
    "x_test=[] # repeat for the test data the steps performed above for training data\n",
    "y_test=[]\n",
    "for i in range(test.shape[0]):\n",
    "    tmp = [enc[j] for j in test.iloc[i,1].split()]\n",
    "    x_test.append(tmp)\n",
    "    if test.iloc[i,0]==0: # re-encode y in the below\n",
    "        y=0\n",
    "    elif test.iloc[i,0]==1: # re-encode y in the below\n",
    "        y=1\n",
    "    else:\n",
    "        y=2\n",
    "    y_test.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti2.iloc[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deciding the maximum vector sequence length\n",
    "Here, I visualize the distribution of word counts in each tweet, then use the 90th percentile. If results aren't satisfactory, I can increase the percentile - to 95%, for example - but the 90th percentile is healthy for preventing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lengths=[]\n",
    "\n",
    "for i in x_train:\n",
    "    lengths.append(len(i))\n",
    "\n",
    "%matplotlib inline\n",
    "plt.hist(lengths,bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sentence with least unigrams (characters) has {} characters.\".format(min(lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"90th percentile of all tweet character count volumes: {}\".format(int(np.percentile(lengths, 90))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Two standard-deviation range: {}\\n\".format([np.asarray(lengths).mean() - 2 * np.asarray(lengths).std(), np.asarray(lengths).mean() + 2 * np.asarray(lengths).std()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing sentence word length by adding the padding and unknown tokens to the sequences (prepared above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "# Because most of the reviews in the histogram above are length 23 or less, setting max_length to 23 words:\n",
    "max_length = 110\n",
    "x_train = sequence.pad_sequences(x_train, maxlen = max_length)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Neural Nets\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist([len(i) for i in x_train])\n",
    "plt.show()\n",
    "### Note that after padding, all sentences are the same length (same number of parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence of Characters Model Output <a class=\"anchor\" id=\"question1ab\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "embedding_vector_length = 80\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(len(dec), embedding_vector_length, input_length=max_length))\n",
    "model1.add(GRU(100, unroll=True, dropout=0.2)) # unroll makes this run faster; units between 100-300\n",
    "model1.add(Dense(3, activation='softmax')) # 3 for the three classes\n",
    "model1.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) # rmsprop did better than adam\n",
    "print(model1.summary())\n",
    "\n",
    "plot_model(model1, to_file='model_plot4a.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GRU = model1.fit(x_train\n",
    "                       , np.array(y_train)\n",
    "                       , validation_data=(x_test, np.array(y_test))\n",
    "                       , callbacks=[callback] # EarlyStopping\n",
    "                       , epochs=20\n",
    "                       , batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = model_GRU.history['val_loss']\n",
    "min_loss_loc = np.where(val_loss==np.min(val_loss))[0][0]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize = (15,7))\n",
    "ax[0].plot(model_GRU.history['val_accuracy'], label = 'val_accuracy')\n",
    "ax[0].plot(model_GRU.history['accuracy'], label = 'accuracy')\n",
    "ax[0].vlines(min_loss_loc, *ax[0].get_ylim(), label = 'min_val_loss')\n",
    "ax[0].set_title('Gated Recurrent Unit Accuracy Curves')\n",
    "ax[0].legend();\n",
    "\n",
    "ax[1].plot(model_GRU.history['val_loss'], label = 'val_loss')\n",
    "ax[1].plot(model_GRU.history['loss'], label = 'loss')\n",
    "ax[1].vlines(min_loss_loc, *ax[1].get_ylim(), label = 'min_val_loss')\n",
    "ax[1].set_title('Gated Recurrent Unit Loss Curves')\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GRU = model1.fit(x_train\n",
    "                       , np.array(y_train)\n",
    "                       , validation_data=(x_test, np.array(y_test))\n",
    "                       , callbacks=[callback]\n",
    "                       , epochs=20\n",
    "                       , batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = model_GRU.history['val_loss']\n",
    "min_loss_loc = np.where(val_loss==np.min(val_loss))[0][0]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize = (15,7))\n",
    "ax[0].plot(model_GRU.history['val_accuracy'], label = 'val_accuracy')\n",
    "ax[0].plot(model_GRU.history['accuracy'], label = 'accuracy')\n",
    "ax[0].vlines(min_loss_loc, *ax[0].get_ylim(), label = 'min_val_loss')\n",
    "ax[0].set_title('Gated Recurrent Unit Accuracy Curves')\n",
    "ax[0].legend();\n",
    "\n",
    "ax[1].plot(model_GRU.history['val_loss'], label = 'val_loss')\n",
    "ax[1].plot(model_GRU.history['loss'], label = 'loss')\n",
    "ax[1].vlines(min_loss_loc, *ax[1].get_ylim(), label = 'min_val_loss')\n",
    "ax[1].set_title('Gated Recurrent Unit Loss Curves')\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GRU = model1.fit(x_train\n",
    "                       , np.array(y_train)\n",
    "                       , validation_data=(x_test, np.array(y_test))\n",
    "                       , callbacks=[callback]\n",
    "                       , epochs=20\n",
    "                       , batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = model_GRU.history['val_loss']\n",
    "min_loss_loc = np.where(val_loss==np.min(val_loss))[0][0]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize = (15,7))\n",
    "ax[0].plot(model_GRU.history['val_accuracy'], label = 'val_accuracy')\n",
    "ax[0].plot(model_GRU.history['accuracy'], label = 'accuracy')\n",
    "ax[0].vlines(min_loss_loc, *ax[0].get_ylim(), label = 'min_val_loss')\n",
    "ax[0].set_title('Gated Recurrent Unit Accuracy Curves')\n",
    "ax[0].legend();\n",
    "\n",
    "ax[1].plot(model_GRU.history['val_loss'], label = 'val_loss')\n",
    "ax[1].plot(model_GRU.history['loss'], label = 'loss')\n",
    "ax[1].vlines(min_loss_loc, *ax[1].get_ylim(), label = 'min_val_loss')\n",
    "ax[1].set_title('Gated Recurrent Unit Loss Curves')\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PART I: Sequence of Bi-gram (2-letter sequences) Model** <a class=\"anchor\" id=\"question1b\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti.iloc[0,1].replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args=pd.DataFrame()\n",
    "args=[]\n",
    "\n",
    "for j in range(len(df_senti)):\n",
    "    args.append(list([df_senti.iloc[j,1].replace(' ', '')[i:i+2] for i in range(len(df_senti.iloc[j,1].replace(' ', '')))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stripping quotes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_frame = pd.Series(args).replace('', '')\n",
    "args_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stripping commas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(len(args_frame)):\n",
    "    args_frame[i] = ' '.join(args_frame[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the first index (and comparing to above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_frame[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the last index (and comparing to above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_frame[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(len(args_frame)):\n",
    "    args_frame[i] = args_frame[i].replace('\\\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(len(args_frame)):\n",
    "    args_frame[i] = args_frame[i].replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirming new length matches original length to ensure no data was inadvertantly truncated before concatenating back to form a character bi-grammed dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(args_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_senti['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti2 = pd.concat([df_senti['sentiment'],args_frame], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_senti2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti2.columns = ['sentiment','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti2.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "\n",
    "for i in df_senti2['text']:\n",
    "    word_list = word_list + i.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc, dec = encode_decode(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti2['y'] = 0\n",
    "df_senti2.loc[df_senti2['sentiment']==1,'y'] = 1\n",
    "df_senti2.loc[df_senti2['sentiment']==2,'y'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n=int(np.floor(df_senti2.shape[0]*0.75)) # 75% for training\n",
    "train = df_senti2[0:n]\n",
    "test = df_senti2[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "\n",
    "for i in range(train.shape[0]):\n",
    "    tmp = [enc[j] for j in train.iloc[i,1].split()] # enc[j]: the j (list expression) is encoding the number for the word in the encoded matrix (i,j) \n",
    "    x_train.append(tmp) # append the newly replaced word\n",
    "    if train.iloc[i,0]==0: # re-encode y in the below\n",
    "        y=0\n",
    "    elif train.iloc[i,0]==1: # re-encode y in the below\n",
    "        y=1\n",
    "    else:\n",
    "        y=2\n",
    "    y_train.append(y) # append the newly encoded y here\n",
    "    \n",
    "x_test=[] # repeat for the test data the steps performed above for training data\n",
    "y_test=[]\n",
    "for i in range(test.shape[0]):\n",
    "    tmp = [enc[j] for j in test.iloc[i,1].split()]\n",
    "    x_test.append(tmp)\n",
    "    if test.iloc[i,0]==0: # re-encode y in the below\n",
    "        y=0\n",
    "    elif test.iloc[i,0]==1: # re-encode y in the below\n",
    "        y=1\n",
    "    else:\n",
    "        y=2\n",
    "    y_test.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lengths=[]\n",
    "\n",
    "for i in x_train:\n",
    "    lengths.append(len(i))\n",
    "\n",
    "%matplotlib inline\n",
    "plt.hist(lengths,bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, because of the volume of bigrams, I've chosen to use the 95th percentile whereas with the unigram approach, I chose to use the 90th percentile. There's less risk of overfitting here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(np.percentile(lengths, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([np.asarray(lengths).mean() - 2 * np.asarray(lengths).std(), np.asarray(lengths).mean() + 2 * np.asarray(lengths).std()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "# Because most of the reviews in the histogram above are length 23 or less, setting max_length to 23 words:\n",
    "max_length = 112\n",
    "x_train = sequence.pad_sequences(x_train, maxlen = max_length)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist([len(i) for i in x_train])\n",
    "plt.show()\n",
    "### Note that after padding, all sentences are the same length (same number of parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence of Bi-Grams Model Output <a class=\"anchor\" id=\"question1bb\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_length = 128\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(len(dec), embedding_vector_length, input_length=max_length))\n",
    "model1.add(GRU(100, unroll=True, dropout=0.2)) # unroll makes this run faster\n",
    "model1.add(Dense(3, activation='softmax'))\n",
    "#model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model1.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "print(model1.summary())\n",
    "\n",
    "plot_model(model1, to_file='model_plot4a.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GRU = model1.fit(x_train\n",
    "                       , np.array(y_train)\n",
    "                       , validation_data=(x_test, np.array(y_test))\n",
    "                       , callbacks=[callback]\n",
    "                       , epochs=20\n",
    "                       , batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = model_GRU.history['val_loss']\n",
    "min_loss_loc = np.where(val_loss==np.min(val_loss))[0][0]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize = (15,7))\n",
    "ax[0].plot(model_GRU.history['val_accuracy'], label = 'val_accuracy')\n",
    "ax[0].plot(model_GRU.history['accuracy'], label = 'accuracy')\n",
    "ax[0].vlines(min_loss_loc, *ax[0].get_ylim(), label = 'min_val_loss')\n",
    "ax[0].set_title('Gated Recurrent Unit Accuracy Curves')\n",
    "ax[0].legend();\n",
    "\n",
    "ax[1].plot(model_GRU.history['val_loss'], label = 'val_loss')\n",
    "ax[1].plot(model_GRU.history['loss'], label = 'loss')\n",
    "ax[1].vlines(min_loss_loc, *ax[1].get_ylim(), label = 'min_val_loss')\n",
    "ax[1].set_title('Gated Recurrent Unit Loss Curves')\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative to the batch size of 32, batch size 16 seems to overfit a little less. Validation metrics are much less outperformed by training with batch size 16 than with batch size 32. Batch size 64 performs the worst, as expected, of the three (16, 32, and 64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GRU = model1.fit(x_train\n",
    "                       , np.array(y_train)\n",
    "                       , validation_data=(x_test, np.array(y_test))\n",
    "                       , callbacks=[callback]\n",
    "                       , epochs=20\n",
    "                       , batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = model_GRU.history['val_loss']\n",
    "min_loss_loc = np.where(val_loss==np.min(val_loss))[0][0]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize = (15,7))\n",
    "ax[0].plot(model_GRU.history['val_accuracy'], label = 'val_accuracy')\n",
    "ax[0].plot(model_GRU.history['accuracy'], label = 'accuracy')\n",
    "ax[0].vlines(min_loss_loc, *ax[0].get_ylim(), label = 'min_val_loss')\n",
    "ax[0].set_title('Gated Recurrent Unit Accuracy Curves')\n",
    "ax[0].legend();\n",
    "\n",
    "ax[1].plot(model_GRU.history['val_loss'], label = 'val_loss')\n",
    "ax[1].plot(model_GRU.history['loss'], label = 'loss')\n",
    "ax[1].vlines(min_loss_loc, *ax[1].get_ylim(), label = 'min_val_loss')\n",
    "ax[1].set_title('Gated Recurrent Unit Loss Curves')\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GRU = model1.fit(x_train\n",
    "                       , np.array(y_train)\n",
    "                       , validation_data=(x_test, np.array(y_test))\n",
    "                       , callbacks=[callback]\n",
    "                       , epochs=20\n",
    "                       , batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = model_GRU.history['val_loss']\n",
    "min_loss_loc = np.where(val_loss==np.min(val_loss))[0][0]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize = (15,7))\n",
    "ax[0].plot(model_GRU.history['val_accuracy'], label = 'val_accuracy')\n",
    "ax[0].plot(model_GRU.history['accuracy'], label = 'accuracy')\n",
    "ax[0].vlines(min_loss_loc, *ax[0].get_ylim(), label = 'min_val_loss')\n",
    "ax[0].set_title('Gated Recurrent Unit Accuracy Curves')\n",
    "ax[0].legend();\n",
    "\n",
    "ax[1].plot(model_GRU.history['val_loss'], label = 'val_loss')\n",
    "ax[1].plot(model_GRU.history['loss'], label = 'loss')\n",
    "ax[1].vlines(min_loss_loc, *ax[1].get_ylim(), label = 'min_val_loss')\n",
    "ax[1].set_title('Gated Recurrent Unit Loss Curves')\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. What is the vector you learned for the following emoji. <a class=\"anchor\" id=\"question1ca\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For parts 2 and 3, I used the findings and pre-trained vectors (in the binary file) from the *Learning Emoji Representations from their Description* research paper and project. I used the Gensim library to load the pre-trained vectors and guage cosine similarity to identify the closest matching emojis.\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1609.08359.pdf\n",
    "</br>\n",
    "GitHub (pre-trained vectors): https://github.com/uclnlp/emoji2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "# display 400 characters of column width\n",
    "pd.options.display.max_colwidth = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cleaning process is the same as for the unigram modeling approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Sentiment.csv')\n",
    "df_senti = df[['sentiment','text']]\n",
    "\n",
    "\n",
    "df_senti['sentiment'].replace(\"Negative\", 0, inplace=True)\n",
    "df_senti['sentiment'].replace(\"Neutral\", 1, inplace=True)\n",
    "df_senti['sentiment'].replace(\"Positive\", 2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti['text'] = df_senti['text'].str.strip('[]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0, len(df_senti)):\n",
    "    if df_senti['text'][i].strip()[0:2] == \"RT\":\n",
    "        df_senti['text'][i] = df_senti['text'][i][2:]\n",
    "\n",
    "for i in np.arange(0,len(df_senti)):\n",
    "    df_senti['text'][i] = ' '.join(word for word in df_senti['text'][i].split(' ') if not word.startswith('http'))\n",
    "\n",
    "\n",
    "for i in np.arange(len(df_senti['text'])):\n",
    "    df_senti['text'][i] = df_senti['text'][i].replace('\\\\n', ' ')\n",
    "    \n",
    "for i in np.arange(len(df_senti['text'])):\n",
    "    df_senti['text'][i] = df_senti['text'][i].replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti.iloc[0,1].replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args=pd.DataFrame()\n",
    "args=[]\n",
    "\n",
    "for j in range(len(df_senti)):\n",
    "    args.append(list([df_senti.iloc[j,1].replace(' ', '')[i:i+1] for i in range(len(df_senti.iloc[j,1].replace(' ', '')))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_frame = pd.Series(args).replace('', '')\n",
    "args_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(len(args_frame)):\n",
    "    args_frame[i] = ' '.join(args_frame[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti2 = pd.concat([df_senti['sentiment'],args_frame], axis=1)\n",
    "df_senti2.columns = ['sentiment','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put words into a dictionary for downstream use\n",
    "import collections\n",
    "def build_dataset(words):\n",
    "    count = collections.Counter(words).most_common() #.most_common(100) to use the 100 most common words; .most_common() means zero is the most common\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "\n",
    "for i in df_senti2['text']:\n",
    "    word_list = word_list + i.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_decode(input):\n",
    "    enc, dec = build_dataset(word_list)\n",
    "    return enc, dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc, dec = encode_decode(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(list(enc.items())[85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in enc:\n",
    "    enc[i] = enc[i]+2 # shift everything by two so you can put in a pad and an unknown in index locations 0 and 1\n",
    "\n",
    "                                                                    ###      ###\n",
    "                                                                    # Encoding #\n",
    "                                                                    ###      ###\n",
    "enc['pad'] = 0\n",
    "\n",
    "# start is useful for more complex architectures to invoke the LSTM to perform certain tasks, like decoding or recognizing the start of a sentence, for example.\n",
    "#enc['<start>'] = 1\n",
    "\n",
    "enc['<unk>'] = 1\n",
    "\n",
    "                                                                    ###      ###\n",
    "                                                                    # Decoding #\n",
    "                                                                    ###      ###\n",
    "\n",
    "# pad and include an unknown for the decoded values as well\n",
    "dec[-2]='<pad>'\n",
    "#dec[-1]='<start>'\n",
    "dec[-1]='<unk>' # this is useful to indicate the LSTM should start decoding, or that this is the start of a sentence, or etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n=int(np.floor(df_senti2.shape[0]*0.75)) # 75% for training\n",
    "train = df_senti2[0:n]\n",
    "test = df_senti2[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti2['y'] = 0\n",
    "df_senti2.loc[df_senti2['sentiment']==1,'y'] = 1\n",
    "df_senti2.loc[df_senti2['sentiment']==2,'y'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "\n",
    "for i in range(train.shape[0]):\n",
    "    tmp = [enc[j] for j in train.iloc[i,1].split()] # enc[j]: the j (list expression) is encoding the number for the word in the encoded matrix (i,j) \n",
    "    x_train.append(tmp) # append the newly replaced word\n",
    "    if train.iloc[i,0]==0: # re-encode y in the below\n",
    "        y=0\n",
    "    elif train.iloc[i,0]==1: # re-encode y in the below\n",
    "        y=1\n",
    "    else:\n",
    "        y=2\n",
    "    y_train.append(y) # append the newly encoded y here\n",
    "    \n",
    "x_test=[] # repeat for the test data the steps performed above for training data\n",
    "y_test=[]\n",
    "for i in range(test.shape[0]):\n",
    "    tmp = [enc[j] for j in test.iloc[i,1].split()]\n",
    "    x_test.append(tmp)\n",
    "    if test.iloc[i,0]==0: # re-encode y in the below\n",
    "        y=0\n",
    "    elif test.iloc[i,0]==1: # re-encode y in the below\n",
    "        y=1\n",
    "    else:\n",
    "        y=2\n",
    "    y_test.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti2.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lengths=[]\n",
    "\n",
    "for i in x_train:\n",
    "    lengths.append(len(i))\n",
    "\n",
    "%matplotlib inline\n",
    "plt.hist(lengths,bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"90th percentile of all tweet character count volumes: {}\".format(int(np.percentile(lengths, 90))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "# Because most of the reviews in the histogram above are length 23 or less, setting max_length to 23 words:\n",
    "max_length = 118\n",
    "x_train = sequence.pad_sequences(x_train, maxlen = max_length)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} rows of {} sequences\".format(x_train.shape[0], x_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Unigram Model Output for Emoji Embedding** <a class=\"anchor\" id=\"question1cb\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "embedding_vector_length = 80\n",
    "model_emoji = Sequential()\n",
    "model_emoji.add(Embedding(len(dec), embedding_vector_length, input_length=max_length))\n",
    "model_emoji.add(GRU(100, unroll=True, dropout=0.2)) # unroll makes this run faster; units between 100-300\n",
    "model_emoji.add(Dense(3, activation='softmax')) # 3 for the three classes\n",
    "model_emoji.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) # rmsprop did better than adam\n",
    "print(model_emoji.summary())\n",
    "\n",
    "plot_model(model_emoji, to_file='model_plot4a.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_emojis = model_emoji.fit(x_train\n",
    "                       , np.array(y_train)\n",
    "                       , validation_data=(x_test, np.array(y_test))\n",
    "                       , callbacks=[callback]\n",
    "                       , epochs=20\n",
    "                       , batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = model_emojis.history['val_loss']\n",
    "min_loss_loc = np.where(val_loss==np.min(val_loss))[0][0]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize = (15,7))\n",
    "ax[0].plot(model_emojis.history['val_accuracy'], label = 'val_accuracy')\n",
    "ax[0].plot(model_emojis.history['accuracy'], label = 'accuracy')\n",
    "ax[0].vlines(min_loss_loc, *ax[0].get_ylim(), label = 'min_val_loss')\n",
    "ax[0].set_title('GRU for Emojis Accuracy Curves')\n",
    "ax[0].legend();\n",
    "\n",
    "ax[1].plot(model_emojis.history['val_loss'], label = 'val_loss')\n",
    "ax[1].plot(model_emojis.history['loss'], label = 'loss')\n",
    "ax[1].vlines(min_loss_loc, *ax[1].get_ylim(), label = 'min_val_loss')\n",
    "ax[1].set_title('GRU for Emojis Loss Curves')\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The vector learned for the emoji: üòÇ  <a class=\"anchor\" id=\"question1cc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the Twitter model trained (includes emojis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_emoji.save('./emoji_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Saved Model <a class=\"anchor\" id=\"question1cd\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model_emoji = keras.models.load_model('./emoji_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model_emoji.get_weights()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle the word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./word_list.txt\", \"wb\") as wl:\n",
    "    pickle.dump(word_list, wl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the word list from pickle (this is needed for the cosine similarity operation) <a class=\"anchor\" id=\"question1ce\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./word_list.txt\", \"rb\") as wl:\n",
    "    word_list = pickle.load(wl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize all characters in the dictionary to visually inspect (and make sure target emoji is present).\n",
    "#### Note: Pull a fresh set of dictionaries without the pad and unknown tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put words into a dictionary for downstream use\n",
    "import collections\n",
    "def build_dataset(words):\n",
    "    count = collections.Counter(words).most_common()\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary\n",
    "\n",
    "def encode_decode(input):\n",
    "    enc, dec = build_dataset(word_list)\n",
    "    return enc, dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc, dec = encode_decode(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('e', 0), ('t', 1), ('a', 2), ('o', 3), ('i', 4), ('n', 5), ('s', 6), ('r', 7), ('l', 8), ('h', 9), ('d', 10), ('u', 11), ('b', 12), ('m', 13), ('c', 14), ('#', 15), ('g', 16), ('p', 17), ('G', 18), ('y', 19), ('D', 20), ('O', 21), ('P', 22), ('w', 23), ('f', 24), ('@', 25), ('.', 26), ('k', 27), (':', 28), ('T', 29), ('v', 30), ('S', 31), ('I', 32), ('R', 33), ('W', 34), ('C', 35), (\"'\", 36), (',', 37), ('A', 38), ('F', 39), ('B', 40), ('N', 41), ('M', 42), ('\"', 43), ('x', 44), ('H', 45), ('?', 46), ('L', 47), ('E', 48), ('‚Ä¶', 49), ('!', 50), ('j', 51), ('J', 52), ('üá∫', 53), ('üá∏', 54), ('z', 55), ('-', 56), ('1', 57), ('K', 58), ('0', 59), ('U', 60), ('2', 61), (';', 62), ('Y', 63), ('&', 64), ('q', 65), ('6', 66), ('/', 67), ('V', 68), ('_', 69), ('3', 70), ('X', 71), ('4', 72), ('5', 73), ('7', 74), ('9', 75), ('8', 76), (')', 77), ('‚Äô', 78), ('(', 79), ('Z', 80), ('Q', 81), ('‚Äú', 82), ('*', 83), ('‚Äù', 84), ('üòÇ', 85), ('%', 86), ('$', 87), ('=', 88), ('[', 89), (']', 90), ('|', 91), ('+', 92), ('üí®', 93), ('Ô∏è', 94), ('‚Äî', 95), ('üèª', 96), ('~', 97), ('üèº', 98), ('‚Äò', 99), ('‚Äì', 100), ('‚ù§', 101), ('¬ª', 102), ('üëé', 103), ('üì¢', 104), ('üëç', 105), ('üëè', 106), ('üôå', 107), ('„Éª', 108), ('¬∑', 109), ('üíÄ', 110), ('üò©', 111), ('üêò', 112), ('üò¥', 113), ('üòÑ', 114), ('üò°', 115), ('üèø', 116), ('üòè', 117), ('üòÄ', 118), ('üò≠', 119), ('üëâ', 120), ('üòä', 121), ('üòé', 122), ('üèæ', 123), ('\\U000fe4e6', 124), ('üòí', 125), ('‚û°', 126), ('‚ñÄ', 127), ('‚Üí', 128), ('¬Ø', 129), ('‚Äº', 130), ('üòç', 131), ('üòâ', 132), ('‚úÖ', 133), ('üòë', 134), ('‚úØ', 135), ('‚Ä¢', 136), ('‚òë', 137), ('üéÄ', 138), ('üòÜ', 139), ('„Äã', 140), ('üòï', 141), ('‚úî', 142), ('üò∂', 143), ('üç∫', 144), ('^', 145), ('üëå', 146), ('üë¥', 147), ('üî®', 148), ('Ÿå', 149), ('‚ñà', 150), ('üí¢', 151), ('‚Üì', 152), ('üòú', 153), ('\\\\', 154), ('„ÉÑ', 155), ('`', 156), ('…ô', 157), ('üé§', 158), ('üòû', 159), ('ÔøΩ', 160), ('üíÅ', 161), ('‚ò¢', 162), ('‚ñ∫', 163), ('‚óÑ', 164), ('‚¨Ü', 165), ('üí•', 166), ('üôè', 167), ('üòÅ', 168), ('üôà', 169), ('‚òû', 170), ('‚òú', 171), ('üéâ', 172), ('üî•', 173), ('üë≠', 174), ('üë®', 175), ('üë∂', 176), ('\\U000fe4ec', 177), ('‚úã', 178), ('üëä', 179), ('üò∞', 180), ('üì∑', 181), ('‚Å∞', 182), ('üò≥', 183), ('üëì', 184), ('Àà', 185), ('Àå', 186), ('ƒÅ', 187), ('üòê', 188), ('üç∑', 189), ('üíß', 190), ('üå∑', 191), ('‚ö°', 192), ('üèΩ', 193), ('üé™', 194), ('üí©', 195), ('‚Üë', 196), ('‚¨á', 197), ('‚Üî', 198), ('üóΩ', 199), ('üòã', 200), ('üò¢', 201), ('üêç', 202), ('‚ôÄ', 203), ('üò¨', 204), ('üòØ', 205), ('üò≤', 206), ('üåç', 207), ('üì≤', 208), ('üíõ', 209), ('‚Äï', 210), ('\\U000fe320', 211), ('\\U000fe327', 212), ('üò†', 213), ('üí™', 214), ('üî™', 215), ('üîá', 216), ('‚áí', 217), ('üöÄ', 218), ('üëã', 219), ('üôä', 220), ('üë∏', 221), ('üëë', 222), ('üòª', 223), ('üë∫', 224), ('üí∞', 225), ('üí∏', 226), ('üö∑', 227), ('üö∫', 228), ('üî´', 229), ('üçî', 230), ('üí£', 231), ('üõÉ', 232), ('üöß', 233), ('üöî', 234), ('üëÄ', 235), ('√Æ', 236), ('≈Ç', 237), ('√©', 238), ('√†', 239)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: This needed to be run twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = {value:key for key, value in enc.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = {value:key for key, value in enc.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have access to the embedding layer explicitly\n",
    "embeddings = model_emoji.get_weights()[0]\n",
    "\n",
    "# `word_to_index` is a mapping (i.e. dict) from words to their index, e.g. `üòÇ`: 85\n",
    "words_embeddings = {w:embeddings[idx] for w, idx in enc.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the learned vector for üòÇ:  <a class=\"anchor\" id=\"question1cf\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.3025325   0.5842908   0.42319667 -0.31405398  0.3698214   0.15363605\n",
      " -0.4177241  -0.22574772  0.00251621  0.00190915 -0.42551884 -0.0626784\n",
      "  0.35473254  0.38380325  0.1223547   0.21410556 -0.23546855  0.16376063\n",
      " -0.26741436 -0.3407969   0.1284697  -0.58715177  0.42320794  0.41040668\n",
      " -0.26324856  0.21925806  0.02229878 -0.00487047  0.08724135  0.2913094\n",
      "  0.01472738  0.16298081  0.5784312  -0.27969462 -0.16617207  0.22300777\n",
      "  0.35038143  0.38679498 -0.29851472 -0.13641584 -0.18616225 -0.27854842\n",
      " -0.12230528 -0.25580463 -0.01578699 -0.15387978 -0.38997325 -0.53054965\n",
      "  0.50691783  0.45597878  0.01528363 -0.30013585  0.1732997   0.34517664\n",
      " -0.13388382 -0.44196326 -0.55923593  0.31625775 -0.30021486 -0.16417497\n",
      " -0.39239502  0.43360528  0.187316   -0.4065224   0.33533433 -0.5363497\n",
      "  0.318125    0.35078213 -0.08221983 -0.02760422 -0.27928853  0.2756848\n",
      " -0.38379908 -0.18375534 -0.5366697   0.08700037  0.29265705  0.43113294\n",
      "  0.01999613  0.29827833]\n"
     ]
    }
   ],
   "source": [
    "# now you can use it like this for example\n",
    "print(words_embeddings['üòÇ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.vocab import Vocab\n",
    "\n",
    "# Adding the vectors into spaCy vocab\n",
    "vocab = Vocab()\n",
    "for word, vector in words_embeddings.items():\n",
    "    vocab.set_vector(word, vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_embeddings.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "gee = list(map(list, words_embeddings.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.array(words_embeddings['üòÇ'].tolist()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.array(words_embeddings['üòÇ'].tolist()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 2., ..., 2., 2., 2.])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances[min_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 2., ..., 2., 2., 2.])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "distances = distance.cdist(np.array(words_embeddings['üòÇ'].tolist()).reshape(-1,1)\n",
    "                           , np.array(gee).reshape(-1,1)\n",
    "                           , \"cosine\"\n",
    "                          )#[0]\n",
    "min_index = np.argmin(distances)\n",
    "min_distance = distances[min_index]\n",
    "max_similarity = 1 - min_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_embeddings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array([words_embeddings[\"üòÇ\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [x for x in words_embeddings.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [words_embeddings[x] for x in ids]\n",
    "vectors = np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12274633225176665583"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most_similar_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar = distance.cdist(p, vectors).argmin()\n",
    "most_similar_char = ids[most_similar]\n",
    "output_char = words_embeddings[most_similar_char]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3025325 ,  0.5842908 ,  0.42319667, -0.31405398,  0.3698214 ,\n",
       "        0.15363605, -0.4177241 , -0.22574772,  0.00251621,  0.00190915,\n",
       "       -0.42551884, -0.0626784 ,  0.35473254,  0.38380325,  0.1223547 ,\n",
       "        0.21410556, -0.23546855,  0.16376063, -0.26741436, -0.3407969 ,\n",
       "        0.1284697 , -0.58715177,  0.42320794,  0.41040668, -0.26324856,\n",
       "        0.21925806,  0.02229878, -0.00487047,  0.08724135,  0.2913094 ,\n",
       "        0.01472738,  0.16298081,  0.5784312 , -0.27969462, -0.16617207,\n",
       "        0.22300777,  0.35038143,  0.38679498, -0.29851472, -0.13641584,\n",
       "       -0.18616225, -0.27854842, -0.12230528, -0.25580463, -0.01578699,\n",
       "       -0.15387978, -0.38997325, -0.53054965,  0.50691783,  0.45597878,\n",
       "        0.01528363, -0.30013585,  0.1732997 ,  0.34517664, -0.13388382,\n",
       "       -0.44196326, -0.55923593,  0.31625775, -0.30021486, -0.16417497,\n",
       "       -0.39239502,  0.43360528,  0.187316  , -0.4065224 ,  0.33533433,\n",
       "       -0.5363497 ,  0.318125  ,  0.35078213, -0.08221983, -0.02760422,\n",
       "       -0.27928853,  0.2756848 , -0.38379908, -0.18375534, -0.5366697 ,\n",
       "        0.08700037,  0.29265705,  0.43113294,  0.01999613,  0.29827833],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-102131903761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0moutput_char\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-173-102131903761>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0moutput_char\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "[k for k, v in words_embeddings.items() if v == output_char]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-d41ec5b22b98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_char\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "dec[output_char]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words_embeddings.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy.spatial import distance\n",
    "# import spacy\n",
    "\n",
    "# input_word = \"üòÇ\"\n",
    "# p = np.array([vocab[input_word].vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = [x for x in vocab.vectors.keys()]\n",
    "# vectors = [vocab.vectors[x] for x in ids]\n",
    "# vectors = np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_similar = distance.cdist(p, vectors).argmin()\n",
    "# most_similar_char = ids[most_similar]\n",
    "# output_char = vocab[most_similar_char].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0308127 , -0.10562409, -0.14084205, ...,  0.14341864,\n",
       "        -0.08657023,  0.09953693],\n",
       "       [ 0.04126022,  0.04071863,  0.02803428, ...,  0.04862085,\n",
       "         0.01575268, -0.01946538],\n",
       "       [-0.00228359, -0.02515168, -0.04487442, ..., -0.08339384,\n",
       "        -0.01983955, -0.15999721],\n",
       "       ...,\n",
       "       [ 0.01612668,  0.04308012, -0.00096083, ..., -0.00385525,\n",
       "         0.02414829, -0.02430508],\n",
       "       [ 0.01106132, -0.00174845, -0.04906845, ..., -0.0057042 ,\n",
       "        -0.019363  ,  0.02408675],\n",
       "       [ 0.03025493, -0.04712554, -0.02480022, ..., -0.00637128,\n",
       "        -0.034205  , -0.01382823]], dtype=float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'üòÇ'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. What is the most similar character for the above emoji  <a class=\"anchor\" id=\"question1da\"></a>\n",
    "## Populating a dataframe with the closest characters to the provided emoji (üòÇ), by cosine distance.\n",
    "## Scale: Values closest to 0 are closest to the emoji (üòÇ). The most similar value is the double-quote (‚Äú)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‚Äú</td>\n",
       "      <td>0.05744379758834839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.1289249062538147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üò¥</td>\n",
       "      <td>0.15175241231918335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*</td>\n",
       "      <td>0.1804565191268921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol             distance\n",
       "0      üòÇ                  0.0\n",
       "1      ‚Äú  0.05744379758834839\n",
       "2      5   0.1289249062538147\n",
       "3      üò¥  0.15175241231918335\n",
       "4      *   0.1804565191268921"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "import pandas as pd\n",
    "\n",
    "dist_df = []\n",
    "\n",
    "for k in dec.keys():\n",
    "    dist_df.append(dec[k] + \"~~~\" + str(scipy.spatial.distance.cosine(words_embeddings['üòÇ'], words_embeddings[dec[k]])))\n",
    "\n",
    "distance_df = pd.DataFrame([sub.split(\"~~~\") for sub in dist_df])\n",
    "\n",
    "distance_df.columns = ['symbol','distance']\n",
    "\n",
    "distance_df = distance_df.sort_values(by='distance').reset_index(drop=True)\n",
    "\n",
    "distance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The most similar emoji: [{}]\\n\\nCosine similarity (not distance) to this emoji: {}\".format(distance_df.iloc[1,0], round(1-float(distance_df.iloc[1,1]), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.test.utils import common_texts, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './emoji2vec.bin'\n",
    "e2v = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_vector = e2v['üòÇ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = e2v.most_similar(\"üòÇ\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The most similar emoji: {}\\n\\nCosine similarity to this emoji: {}%\".format(result[0][0], (100*round(result[0][1], 4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PART II**<a class=\"anchor\" id=\"question1e\"></a>\n",
    "# 4. Build a Universal Sentence Encoder (USE) Model and an RNN (RNN, LSTM, GRU, etc.) model for the following data set. Accuracy must be above 50%. Compare the results of the two in terms of time and accuracy.\n",
    "http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip (first column is the polarity 0:negative, 4:positive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Comparative Performance Analysis:</u> **Universal Sentence Encoder** versus **Gated Recurrent Unit**\n",
    "\n",
    "### Overall, the results were very similar for the Universal Sentence Encoder and the Gated Recurrent Unit. However, the USE appeared to be less prone to overfitting; model and training accuracy had less divergence as batch size was increased for the USE models compared to the GRU models. Conversely, as batch size was increased, training loss decreased much more compared to validation loss for the USE models compared to the GRU models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = {\n",
    "    'Model':['Universal Sentence Encoder (batch size 128)','Universal Sentence Encoder (batch size 512)','Universal Sentence Encoder (batch size 2048)'\n",
    "             ,'Gated Recurrent Unit (batch size 512)','Gated Recurrent Unit (batch size 2048)'], \n",
    "    'Mean Accuracy (Training)':['0.8055','0.8016','0.8175', '0.8714','0.9442'], \n",
    "    'Mean Accuracy (Validation)':['0.8018','0.7998', '0.8037','0.7956','0.7838'],\n",
    "    'Mean Accuracy Ratio (Training/Validation)':['1.0046', '1.0023', '1.0172','1.0953','1.2046'],\n",
    "    'Mean Loss (Training)':['0.4181','0.4255', '0.3982', '0.2997','0.1424'], \n",
    "    'Mean Loss (Validation)':['0.4258','0.4278', '0.4216', '0.4629','0.5859'],\n",
    "    'Mean Loss Ratio (Training/Validation)':['0.9819','0.9946','0.9445','0.6474','0.2430']}\n",
    "\n",
    "pd.DataFrame(summary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PART II: Universal Sentence Encoder Models**<a class=\"anchor\" id=\"question1ea\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tensorflow Version:\\n{}\\n\\nTensor-Hub Version:\\n{}\".format(tf.__version__, hub.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for physical_device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_test = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\", trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./training.1600000.processed.noemoticon.csv', encoding = \"ISO-8859-1\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[0,5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset needs to be shuffled. The original dataset is split - the first half is all class 0 and the second half is all class 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1.0, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bash to shuffle\n",
    "#!shuf training.1600000.processed.noemoticon.csv > training.1600000.processed.noemoticon_shuffled.csv\n",
    "# data = pd.read_csv('~/Desktop/DS7337 Natural Language Processing/Final_Exam/PART2_Data/training.1600000.processed.noemoticon_shuffled.csv', encoding = \"ISO-8859-1\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['polarity','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['polarity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.polarity[data.polarity == 4] = 1\n",
    "data.polarity[data.polarity == 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['polarity'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is balanced on a perfect 50/50 split and has been randomly shuffled so I'll use a 50/50 test/validation split (downstream) since this gives a little more to the validation than a 75/25 (or similar) split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Balance of data classes: {}%\".format(100*(round(data[data.polarity == 1].shape[0]/data.shape[0], 4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data\n",
    "\n",
    "Because this data appears to be from Twitter or some other platform that uses hashtags (\"#\") and mentions (\"@\"). Also, I'll leave only spaces and alphanumeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].str.strip().str.lower()\n",
    "data.text = data.text.str.replace(r\"[^a-zA-Z0-9 ]\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For retweets, I'm removing the \"RT\" values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0, len(data)):\n",
    "    if data['text'][i].strip()[0:2] == \"RT\":\n",
    "        data['text'][i] = data['text'][i][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(np.floor(data.shape[0]*0.5)) # 50% for training\n",
    "train_df = data[0:n]\n",
    "test_df = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['polarity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['polarity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lengths=[]\n",
    "\n",
    "for i in data['text']:\n",
    "    lengths.append(len(i))\n",
    "\n",
    "%matplotlib inline\n",
    "plt.hist(lengths,bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(np.percentile(lengths, 95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two standard deviations cover 95 percent of the data in a normal distribution. Because this distribution is not perfectly normal, there is a slight difference (129 vs 139) when considering both tails (139) versus only the right tail (129). Nonetheless, this difference is relatively negligible.\n",
    "\n",
    "However, because USE converts everything to 51 and the maximum original length is 179, I won't limit the sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([np.asarray(lengths).mean() - 2 * np.asarray(lengths).std(), np.asarray(lengths).mean() + 2 * np.asarray(lengths).std()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df['text'].tolist()\n",
    "X_train = [' '.join(t.split()[0:179]) for t in X_train]\n",
    "X_train = np.array(X_train, dtype=object)[:, np.newaxis]\n",
    "y_train = train_df['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df['text'].tolist()\n",
    "X_test = [' '.join(t.split()[0:179]) for t in X_test]\n",
    "X_test = np.array(X_test, dtype=object)[:, np.newaxis]\n",
    "y_test = test_df['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.concat([y_train, y_test], axis=0)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Data Length: {}\\nValidation Data Length:{}\".format(X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UniversalEmbedding(x):\n",
    "    return use_test(tf.squeeze(tf.cast(x, tf.string)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Sentence Encoder Model Results <a class=\"anchor\" id=\"question1eb\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "embed_size = 512 # since USE produces 512 vector lengths regardless of input size\n",
    "\n",
    "input_text = Input(shape=(), dtype=tf.string) # leaving this as floating point\n",
    "\n",
    "embedding = hub.KerasLayer(UniversalEmbedding, output_shape=(embed_size,))(input_text)\n",
    "\n",
    "x = Dense(256, activation='relu')(embedding)\n",
    "output = Dense(1,activation='sigmoid',name='output')(x) # sigmoid for 2-classes\n",
    "\n",
    "model = tf.keras.Model(inputs=input_text, outputs=[output])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  callbacks=[callback],\n",
    "                  metrics=['accuracy'])\n",
    "model.summary()\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size 128 yeilds mean runtime of 123.6 seconds, mean training accuracy 0.8055, and mean validation accuracy of 0.8018:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, np.array(y_train),\n",
    "                 batch_size = 128,\n",
    "                 epochs = 5,\n",
    "                 callbacks = [callback],\n",
    "                 validation_data=(X_test, np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = hist.history['val_loss']\n",
    "min_loss_loc = np.where(val_loss==np.min(val_loss))[0][0]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize = (15,7))\n",
    "ax[0].plot(hist.history['val_accuracy'], label = 'val_accuracy')\n",
    "ax[0].plot(hist.history['accuracy'], label = 'accuracy')\n",
    "ax[0].vlines(min_loss_loc, *ax[0].get_ylim(), label = 'min_val_loss')\n",
    "ax[0].set_title('Universal Sentence Encoder Accuracy Curves')\n",
    "ax[0].legend();\n",
    "\n",
    "ax[1].plot(hist.history['val_loss'], label = 'val_loss')\n",
    "ax[1].plot(hist.history['loss'], label = 'loss')\n",
    "ax[1].vlines(min_loss_loc, *ax[1].get_ylim(), label = 'min_val_loss')\n",
    "ax[1].set_title('Universal Sentence Encoder Loss Curves')\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size 512 yeilds mean runtime of 70.8 seconds, mean training accuracy 0.8016, and mean validation accuracy of 0.7998:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, np.array(y_train),\n",
    "                 batch_size = 512,\n",
    "                 epochs = 5,\n",
    "                 callbacks = [callback],\n",
    "                 validation_data=(X_test, np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = hist.history['val_loss']\n",
    "min_loss_loc = np.where(val_loss==np.min(val_loss))[0][0]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize = (15,7))\n",
    "ax[0].plot(hist.history['val_accuracy'], label = 'val_accuracy')\n",
    "ax[0].plot(hist.history['accuracy'], label = 'accuracy')\n",
    "ax[0].vlines(min_loss_loc, *ax[0].get_ylim(), label = 'min_val_loss')\n",
    "ax[0].set_title('Universal Sentence Encoder Accuracy Curves')\n",
    "ax[0].legend();\n",
    "\n",
    "ax[1].plot(hist.history['val_loss'], label = 'val_loss')\n",
    "ax[1].plot(hist.history['loss'], label = 'loss')\n",
    "ax[1].vlines(min_loss_loc, *ax[1].get_ylim(), label = 'min_val_loss')\n",
    "ax[1].set_title('Universal Sentence Encoder Loss Curves')\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size 2048 yeilds mean runtime of 51.2 seconds, mean training accuracy 0.8175, and mean validation accuracy of 0.8037:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, np.array(y_train),\n",
    "                 batch_size = 2048,\n",
    "                 epochs = 5,\n",
    "                 callbacks = [callback],\n",
    "                 validation_data=(X_test, np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = hist.history['val_loss']\n",
    "min_loss_loc = np.where(val_loss==np.min(val_loss))[0][0]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize = (15,7))\n",
    "ax[0].plot(hist.history['val_accuracy'], label = 'val_accuracy')\n",
    "ax[0].plot(hist.history['accuracy'], label = 'accuracy')\n",
    "ax[0].vlines(min_loss_loc, *ax[0].get_ylim(), label = 'min_val_loss')\n",
    "ax[0].set_title('Universal Sentence Encoder Accuracy Curves')\n",
    "ax[0].legend();\n",
    "\n",
    "ax[1].plot(hist.history['val_loss'], label = 'val_loss')\n",
    "ax[1].plot(hist.history['loss'], label = 'loss')\n",
    "ax[1].vlines(min_loss_loc, *ax[1].get_ylim(), label = 'min_val_loss')\n",
    "ax[1].set_title('Universal Sentence Encoder Loss Curves')\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PART II: Gated Recurrent Unit Models** <a class=\"anchor\" id=\"question1ec\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for physical_device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./training.1600000.processed.noemoticon.csv', encoding = \"ISO-8859-1\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1.0, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[0,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['polarity','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.polarity[data.polarity == 4] = 1\n",
    "data.polarity[data.polarity == 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['polarity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Balance of data classes: {}%\".format(100*(round(data[data.polarity == 1].shape[0]/data.shape[0], 4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].str.strip().str.lower()\n",
    "data.text = data.text.str.replace(r\"[^a-zA-Z0-9 ]\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0, len(data)):\n",
    "    if data['text'][i].strip()[0:2] == \"RT\":\n",
    "        data['text'][i] = data['text'][i][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(np.floor(data.shape[0]*0.5)) # 50% for training\n",
    "train_df = data[0:n]\n",
    "test_df = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['polarity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put words into a dictionary for downstream use\n",
    "import collections\n",
    "\n",
    "def build_dataset(words):\n",
    "    count = collections.Counter(words).most_common() #.most_common(100) to use the 100 most common words; .most_common() means zero is the most common\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list=[]\n",
    "flat_list = []\n",
    "\n",
    "for i in np.arange(len(data)):\n",
    "    word_list.append(data['text'][i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = []\n",
    "for sublist in word_list:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = flat_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_unique = set(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_decode(input):\n",
    "    enc, dec = build_dataset(word_list)\n",
    "    return enc, dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc, dec = encode_decode(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in enc:\n",
    "    enc[i] = enc[i]+2 # shift everything by two so you can put in a pad and an unknown in index locations 0 and 1\n",
    "\n",
    "                                                                    ###      ###\n",
    "                                                                    # Encoding #\n",
    "                                                                    ###      ###\n",
    "enc['pad'] = 0\n",
    "\n",
    "# start is useful for more complex architectures to invoke the LSTM to perform certain tasks, like decoding or recognizing the start of a sentence, for example.\n",
    "#enc['<start>'] = 1\n",
    "\n",
    "enc['<unk>'] = 1\n",
    "\n",
    "                                                                    ###      ###\n",
    "                                                                    # Decoding #\n",
    "                                                                    ###      ###\n",
    "\n",
    "# pad and include an unknown for the decoded values as well\n",
    "dec[-2]='<pad>'\n",
    "#dec[-1]='<start>'\n",
    "dec[-1]='<unk>' # this is useful to indicate the LSTM should start decoding, or that this is the start of a sentence, or etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['y'] = 0\n",
    "data.loc[data['polarity']==1,'y'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Balance of data classes: {}%\".format(100*(round(data[data.polarity == 1].shape[0]/data.shape[0], 4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n=int(np.floor(data.shape[0]*0.50)) # 50% for training since target classes are balanced\n",
    "train = data[0:n]\n",
    "test = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "\n",
    "for i in range(train.shape[0]):\n",
    "    tmp = [enc[j] for j in train.iloc[i,1].split()] # enc[j]: the j (list expression) is encoding the number for the word in the encoded matrix (i,j) \n",
    "    x_train.append(tmp) # append the newly replaced word\n",
    "    if train.iloc[i,0]==0: # re-encode y in the below\n",
    "        y=0\n",
    "    else:\n",
    "        y=1\n",
    "    y_train.append(y) # append the newly encoded y here\n",
    "    \n",
    "x_test=[] # repeat for the test data the steps performed above for training data\n",
    "y_test=[]\n",
    "for i in range(test.shape[0]):\n",
    "    tmp = [enc[j] for j in test.iloc[i,1].split()]\n",
    "    x_test.append(tmp)\n",
    "    if test.iloc[i,0]==0: # re-encode y in the below\n",
    "        y=0\n",
    "    else:\n",
    "        y=1\n",
    "    y_test.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first time this runs, i-2 will remove the decoded pad and unknown variables used to prevent over-fitting\n",
    "[dec[i-2] for i in x_train[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lengths=[]\n",
    "\n",
    "for i in data['text']:\n",
    "    lengths.append(len(i))\n",
    "\n",
    "%matplotlib inline\n",
    "plt.hist(lengths,bins=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(np.percentile(lengths, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "max_length = 129\n",
    "x_train = sequence.pad_sequences(x_train, maxlen = max_length)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist([len(i) for i in x_train])\n",
    "plt.show()\n",
    "### Note that after padding, all sentences are the same length (same number of parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 131,585 total (and trainable) parameters in the Universal Sentence Encoder model. There are 67,25,541 total (and trainable) parameters in this Gated Recurrent Unit model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gated Recurrent Unit Model Results <a class=\"anchor\" id=\"question1ed\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "max_length = 129\n",
    "embedding_vector_length = 180\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(len(dec), embedding_vector_length, input_length=max_length)) # create the embedding vectors\n",
    "model1.add(GRU(300, unroll=True, dropout=0.2)) # unroll makes this run faster; units between 100-300\n",
    "model1.add(Dense(1, activation='sigmoid')) # 1 for the two classes\n",
    "model1.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy']) # binary crossentropy for the two classes + sigmoid\n",
    "print(model1.summary())\n",
    "\n",
    "plot_model(model1, to_file='model_plot4a.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(sanity check to make sure input variable datasets are rectangular and there are no ragged edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectangular(List):\n",
    "    n = List\n",
    "    for i in n:\n",
    "        if len(i) != len(n[0]):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The data is rectangular (True or False):\\n{}\".format(rectangular(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size 512 yeilds mean runtime of 1098.8 seconds, mean training accuracy 0.8714, and mean validation accuracy of 0.7956:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "model_GRU = model1.fit(x_train\n",
    "                       , np.array(y_train)\n",
    "                       , validation_data=(x_test, np.array(y_test))\n",
    "                       , callbacks = [callback]\n",
    "                       , epochs=5\n",
    "                       , batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = model_GRU.history['val_loss']\n",
    "min_loss_loc = np.where(val_loss==np.min(val_loss))[0][0]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize = (15,7))\n",
    "ax[0].plot(model_GRU.history['val_accuracy'], label = 'val_accuracy')\n",
    "ax[0].plot(model_GRU.history['accuracy'], label = 'accuracy')\n",
    "ax[0].vlines(min_loss_loc, *ax[0].get_ylim(), label = 'min_val_loss')\n",
    "ax[0].set_title('GRU Accuracy Curves')\n",
    "ax[0].legend();\n",
    "\n",
    "ax[1].plot(model_GRU.history['val_loss'], label = 'val_loss')\n",
    "ax[1].plot(model_GRU.history['loss'], label = 'loss')\n",
    "ax[1].vlines(min_loss_loc, *ax[1].get_ylim(), label = 'min_val_loss')\n",
    "ax[1].set_title('GRU Loss Curves')\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size 2048 yeilds mean runtime of 336.6 seconds, mean training accuracy 0.9442, and mean validation accuracy of 0.7838:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "model_GRU = model1.fit(x_train\n",
    "                       , np.array(y_train)\n",
    "                       , validation_data=(x_test, np.array(y_test))\n",
    "                       , callbacks = [callback]\n",
    "                       , epochs=5\n",
    "                       , batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = model_GRU.history['val_loss']\n",
    "min_loss_loc = np.where(val_loss==np.min(val_loss))[0][0]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize = (15,7))\n",
    "ax[0].plot(model_GRU.history['val_accuracy'], label = 'val_accuracy')\n",
    "ax[0].plot(model_GRU.history['accuracy'], label = 'accuracy')\n",
    "ax[0].vlines(min_loss_loc, *ax[0].get_ylim(), label = 'min_val_loss')\n",
    "ax[0].set_title('GRU Accuracy Curves')\n",
    "ax[0].legend();\n",
    "\n",
    "ax[1].plot(model_GRU.history['val_loss'], label = 'val_loss')\n",
    "ax[1].plot(model_GRU.history['loss'], label = 'loss')\n",
    "ax[1].vlines(min_loss_loc, *ax[1].get_ylim(), label = 'min_val_loss')\n",
    "ax[1].set_title('GRU Loss Curves')\n",
    "ax[1].legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
